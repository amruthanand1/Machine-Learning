{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from scipy import stats\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_rooms</th>\n",
       "      <th>floor_on</th>\n",
       "      <th>total_floors</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>pincode</th>\n",
       "      <th>balkon</th>\n",
       "      <th>terrasse</th>\n",
       "      <th>garten</th>\n",
       "      <th>Gaste-WC</th>\n",
       "      <th>Aufzug</th>\n",
       "      <th>wohung</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>living_area_m2</th>\n",
       "      <th>transform_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>8.536559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16515</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>8.579834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13357</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>8.331774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      number_of_rooms  floor_on  total_floors  bedroom  pincode  balkon  \\\n",
       "8594              1.0         0             3        1    10823       0   \n",
       "6658              3.0         0             0        0    16515       0   \n",
       "4485              2.5         1             1        1    13357       1   \n",
       "\n",
       "      terrasse  garten  Gaste-WC  Aufzug  wohung  construction_year  \\\n",
       "8594         0       0         0       0       1               1900   \n",
       "6658         1       1         0       0       0                  0   \n",
       "4485         1       1         0       1       1               2020   \n",
       "\n",
       "      living_area_m2  transform_price  \n",
       "8594        3.465736         8.536559  \n",
       "6658        4.510860         8.579834  \n",
       "4485        4.290459         8.331774  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'F:\\amruth\\after_preprocess_data.csv', encoding = 'iso-8859-1')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data[['transform_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12424, 13), (12424, 1), (319, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.025, random_state = 0)\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1), input_shape = [None]),\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu'),\n",
    "    #tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
    "    #tf.keras.layers.SimpleRNN(40, return_sequences = True),\n",
    "    #tf.keras.layers.SimpleRNN(20),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(5,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epochs: 1e-5 * 10**(epochs / 20))\n",
    "model.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12424/12424 [==============================] - 8s 670us/sample - loss: 65.8941 - mae: 8.1022\n",
      "Epoch 2/50\n",
      "12424/12424 [==============================] - 7s 543us/sample - loss: 51.9378 - mae: 7.1906\n",
      "Epoch 3/50\n",
      "12424/12424 [==============================] - 7s 559us/sample - loss: 35.0406 - mae: 5.8961\n",
      "Epoch 4/50\n",
      "12424/12424 [==============================] - 7s 546us/sample - loss: 24.4490 - mae: 4.9209\n",
      "Epoch 5/50\n",
      "12424/12424 [==============================] - 6s 518us/sample - loss: 16.2971 - mae: 4.0087\n",
      "Epoch 6/50\n",
      "12424/12424 [==============================] - 6s 502us/sample - loss: 10.1204 - mae: 3.1485\n",
      "Epoch 7/50\n",
      "12424/12424 [==============================] - 7s 553us/sample - loss: 5.5427 - mae: 2.3068\n",
      "Epoch 8/50\n",
      "12424/12424 [==============================] - 6s 453us/sample - loss: 2.4138 - mae: 1.4875\n",
      "Epoch 9/50\n",
      "12424/12424 [==============================] - 7s 524us/sample - loss: 0.7921 - mae: 0.8041\n",
      "Epoch 10/50\n",
      "12424/12424 [==============================] - 6s 453us/sample - loss: 0.2729 - mae: 0.4316\n",
      "Epoch 11/50\n",
      "12424/12424 [==============================] - 6s 463us/sample - loss: 0.1702 - mae: 0.3157\n",
      "Epoch 12/50\n",
      "12424/12424 [==============================] - 6s 459us/sample - loss: 0.1589 - mae: 0.2968\n",
      "Epoch 13/50\n",
      "12424/12424 [==============================] - 6s 450us/sample - loss: 0.1577 - mae: 0.2942\n",
      "Epoch 14/50\n",
      "12424/12424 [==============================] - 6s 484us/sample - loss: 0.1568 - mae: 0.2933\n",
      "Epoch 15/50\n",
      "12424/12424 [==============================] - ETA: 0s - loss: 0.1560 - mae: 0.292 - 6s 479us/sample - loss: 0.1560 - mae: 0.2921\n",
      "Epoch 16/50\n",
      "12424/12424 [==============================] - 6s 479us/sample - loss: 0.1549 - mae: 0.2912\n",
      "Epoch 17/50\n",
      "12424/12424 [==============================] - 7s 539us/sample - loss: 0.1537 - mae: 0.2899\n",
      "Epoch 18/50\n",
      "12424/12424 [==============================] - 7s 545us/sample - loss: 0.1520 - mae: 0.2881\n",
      "Epoch 19/50\n",
      "12424/12424 [==============================] - 8s 627us/sample - loss: 0.1492 - mae: 0.2858\n",
      "Epoch 20/50\n",
      "12424/12424 [==============================] - 7s 591us/sample - loss: 0.1443 - mae: 0.2809\n",
      "Epoch 21/50\n",
      "12424/12424 [==============================] - 7s 567us/sample - loss: 0.1375 - mae: 0.2743\n",
      "Epoch 22/50\n",
      "12424/12424 [==============================] - 7s 598us/sample - loss: 0.1289 - mae: 0.2660\n",
      "Epoch 23/50\n",
      "12424/12424 [==============================] - 7s 596us/sample - loss: 0.1231 - mae: 0.2607\n",
      "Epoch 24/50\n",
      "12424/12424 [==============================] - 9s 753us/sample - loss: 0.1200 - mae: 0.2576\n",
      "Epoch 25/50\n",
      "12424/12424 [==============================] - 8s 604us/sample - loss: 0.1184 - mae: 0.2556s - loss: 0.1189 - mae\n",
      "Epoch 26/50\n",
      "12424/12424 [==============================] - 8s 628us/sample - loss: 0.1166 - mae: 0.2538\n",
      "Epoch 27/50\n",
      "12424/12424 [==============================] - 8s 640us/sample - loss: 0.1152 - mae: 0.2513\n",
      "Epoch 28/50\n",
      "12424/12424 [==============================] - 7s 596us/sample - loss: 0.1134 - mae: 0.2490\n",
      "Epoch 29/50\n",
      "12424/12424 [==============================] - 8s 633us/sample - loss: 0.1117 - mae: 0.2466\n",
      "Epoch 30/50\n",
      "12424/12424 [==============================] - 8s 638us/sample - loss: 0.1109 - mae: 0.2447\n",
      "Epoch 31/50\n",
      "12424/12424 [==============================] - 7s 596us/sample - loss: 0.1093 - mae: 0.2427\n",
      "Epoch 32/50\n",
      "12424/12424 [==============================] - 7s 574us/sample - loss: 0.1090 - mae: 0.2410\n",
      "Epoch 33/50\n",
      "12424/12424 [==============================] - 7s 566us/sample - loss: 0.1079 - mae: 0.2403\n",
      "Epoch 34/50\n",
      "12424/12424 [==============================] - 7s 566us/sample - loss: 0.1069 - mae: 0.2379\n",
      "Epoch 35/50\n",
      "12424/12424 [==============================] - 8s 615us/sample - loss: 0.1086 - mae: 0.2406\n",
      "Epoch 36/50\n",
      "12424/12424 [==============================] - 7s 579us/sample - loss: 0.1072 - mae: 0.2389\n",
      "Epoch 37/50\n",
      "12424/12424 [==============================] - 7s 559us/sample - loss: 0.1080 - mae: 0.2400\n",
      "Epoch 38/50\n",
      "12424/12424 [==============================] - 7s 565us/sample - loss: 0.1080 - mae: 0.2404\n",
      "Epoch 39/50\n",
      "12424/12424 [==============================] - 7s 596us/sample - loss: 0.1100 - mae: 0.2428\n",
      "Epoch 40/50\n",
      "12424/12424 [==============================] - 7s 531us/sample - loss: 0.1063 - mae: 0.2380s - lo\n",
      "Epoch 41/50\n",
      "12424/12424 [==============================] - 6s 515us/sample - loss: 0.1077 - mae: 0.2406\n",
      "Epoch 42/50\n",
      "12424/12424 [==============================] - 6s 514us/sample - loss: 0.1058 - mae: 0.2372\n",
      "Epoch 43/50\n",
      "12424/12424 [==============================] - 7s 598us/sample - loss: 0.1083 - mae: 0.2408\n",
      "Epoch 44/50\n",
      "12424/12424 [==============================] - 6s 515us/sample - loss: 0.1070 - mae: 0.2396\n",
      "Epoch 45/50\n",
      "12424/12424 [==============================] - 7s 531us/sample - loss: 0.1088 - mae: 0.2418\n",
      "Epoch 46/50\n",
      "12424/12424 [==============================] - 6s 510us/sample - loss: 0.1078 - mae: 0.2408s - loss: 0.1061 - \n",
      "Epoch 47/50\n",
      "12424/12424 [==============================] - 6s 523us/sample - loss: 0.1086 - mae: 0.2409\n",
      "Epoch 48/50\n",
      "12424/12424 [==============================] - 7s 536us/sample - loss: 0.1063 - mae: 0.2390\n",
      "Epoch 49/50\n",
      "12424/12424 [==============================] - 6s 495us/sample - loss: 0.1064 - mae: 0.2387\n",
      "Epoch 50/50\n",
      "12424/12424 [==============================] - 6s 496us/sample - loss: 0.1109 - mae: 0.2449\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train, epochs=50, callbacks = [lr_schedule])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x234ccc82b88>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = 1e-5 * (10 ** (np.arange(50) / 20))\n",
    "plt.semilogx(lrs, history.history[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12424/12424 [==============================] - 7s 565us/sample - loss: 51.6360 - mae: 7.1228\n",
      "Epoch 2/50\n",
      "12424/12424 [==============================] - 6s 523us/sample - loss: 18.4232 - mae: 4.2123\n",
      "Epoch 3/50\n",
      "12424/12424 [==============================] - 6s 484us/sample - loss: 4.4894 - mae: 2.0161\n",
      "Epoch 4/50\n",
      "12424/12424 [==============================] - 6s 452us/sample - loss: 0.7278 - mae: 0.7480\n",
      "Epoch 5/50\n",
      "12424/12424 [==============================] - 6s 445us/sample - loss: 0.1975 - mae: 0.3483\n",
      "Epoch 6/50\n",
      "12424/12424 [==============================] - 6s 502us/sample - loss: 0.1620 - mae: 0.3003s - loss: 0.1585 - mae: 0.301 - ETA: 1s - loss: 0.1583 - mae: - ETA: 0s - loss: \n",
      "Epoch 7/50\n",
      "12424/12424 [==============================] - 7s 537us/sample - loss: 0.1608 - mae: 0.2974s - loss: 0.1608 - mae: 0.297\n",
      "Epoch 8/50\n",
      "12424/12424 [==============================] - 7s 561us/sample - loss: 0.1604 - mae: 0.2969\n",
      "Epoch 9/50\n",
      "12424/12424 [==============================] - 7s 588us/sample - loss: 0.1598 - mae: 0.2963\n",
      "Epoch 10/50\n",
      "12424/12424 [==============================] - 8s 618us/sample - loss: 0.1592 - mae: 0.2956\n",
      "Epoch 11/50\n",
      "12424/12424 [==============================] - 7s 583us/sample - loss: 0.1584 - mae: 0.2947\n",
      "Epoch 12/50\n",
      "12424/12424 [==============================] - 7s 576us/sample - loss: 0.1576 - mae: 0.2942\n",
      "Epoch 13/50\n",
      "12424/12424 [==============================] - 7s 568us/sample - loss: 0.1564 - mae: 0.2927\n",
      "Epoch 14/50\n",
      "12424/12424 [==============================] - 7s 566us/sample - loss: 0.1549 - mae: 0.2915\n",
      "Epoch 15/50\n",
      "12424/12424 [==============================] - 8s 615us/sample - loss: 0.1530 - mae: 0.2895\n",
      "Epoch 16/50\n",
      "12424/12424 [==============================] - 7s 568us/sample - loss: 0.1502 - mae: 0.2868\n",
      "Epoch 17/50\n",
      "12424/12424 [==============================] - 7s 571us/sample - loss: 0.1450 - mae: 0.2818\n",
      "Epoch 18/50\n",
      "12424/12424 [==============================] - 7s 590us/sample - loss: 0.1386 - mae: 0.2756\n",
      "Epoch 19/50\n",
      "12424/12424 [==============================] - 7s 550us/sample - loss: 0.1325 - mae: 0.2697\n",
      "Epoch 20/50\n",
      "12424/12424 [==============================] - 7s 597us/sample - loss: 0.1279 - mae: 0.2656\n",
      "Epoch 21/50\n",
      "12424/12424 [==============================] - 6s 512us/sample - loss: 0.1249 - mae: 0.2629\n",
      "Epoch 22/50\n",
      "12424/12424 [==============================] - 6s 505us/sample - loss: 0.1232 - mae: 0.2611\n",
      "Epoch 23/50\n",
      "12424/12424 [==============================] - 7s 567us/sample - loss: 0.1217 - mae: 0.2598\n",
      "Epoch 24/50\n",
      "12424/12424 [==============================] - 7s 566us/sample - loss: 0.1208 - mae: 0.2587\n",
      "Epoch 25/50\n",
      "12424/12424 [==============================] - 7s 538us/sample - loss: 0.1198 - mae: 0.2576\n",
      "Epoch 26/50\n",
      "12424/12424 [==============================] - 7s 540us/sample - loss: 0.1189 - mae: 0.2567\n",
      "Epoch 27/50\n",
      "12424/12424 [==============================] - 7s 572us/sample - loss: 0.1178 - mae: 0.2551s - loss: 0.1189 \n",
      "Epoch 28/50\n",
      "12424/12424 [==============================] - 6s 511us/sample - loss: 0.1167 - mae: 0.2534\n",
      "Epoch 29/50\n",
      "12424/12424 [==============================] - 6s 500us/sample - loss: 0.1149 - mae: 0.2509s - loss: 0.1141 - ma\n",
      "Epoch 30/50\n",
      "12424/12424 [==============================] - 6s 499us/sample - loss: 0.1132 - mae: 0.2485\n",
      "Epoch 31/50\n",
      "12424/12424 [==============================] - 6s 493us/sample - loss: 0.1121 - mae: 0.2469\n",
      "Epoch 32/50\n",
      "12424/12424 [==============================] - 6s 494us/sample - loss: 0.1112 - mae: 0.2457\n",
      "Epoch 33/50\n",
      "12424/12424 [==============================] - 7s 577us/sample - loss: 0.1106 - mae: 0.2445\n",
      "Epoch 34/50\n",
      "12424/12424 [==============================] - 7s 577us/sample - loss: 0.1103 - mae: 0.2441\n",
      "Epoch 35/50\n",
      "12424/12424 [==============================] - 7s 553us/sample - loss: 0.1097 - mae: 0.2432\n",
      "Epoch 36/50\n",
      "12424/12424 [==============================] - 8s 620us/sample - loss: 0.1092 - mae: 0.2424\n",
      "Epoch 37/50\n",
      "12424/12424 [==============================] - 8s 679us/sample - loss: 0.1090 - mae: 0.2419\n",
      "Epoch 38/50\n",
      "12424/12424 [==============================] - 8s 614us/sample - loss: 0.1090 - mae: 0.2420\n",
      "Epoch 39/50\n",
      "12424/12424 [==============================] - 7s 569us/sample - loss: 0.1086 - mae: 0.2417s - lo\n",
      "Epoch 40/50\n",
      "12424/12424 [==============================] - 8s 640us/sample - loss: 0.1082 - mae: 0.2408\n",
      "Epoch 41/50\n",
      "12424/12424 [==============================] - 9s 740us/sample - loss: 0.1078 - mae: 0.2402\n",
      "Epoch 42/50\n",
      "12424/12424 [==============================] - 8s 617us/sample - loss: 0.1077 - mae: 0.2404s - loss: 0.1 - ETA: 1s - \n",
      "Epoch 43/50\n",
      "12424/12424 [==============================] - 6s 512us/sample - loss: 0.1077 - mae: 0.2402\n",
      "Epoch 44/50\n",
      "12424/12424 [==============================] - 7s 570us/sample - loss: 0.1075 - mae: 0.2402\n",
      "Epoch 45/50\n",
      "12424/12424 [==============================] - 7s 579us/sample - loss: 0.1072 - mae: 0.2393\n",
      "Epoch 46/50\n",
      "12424/12424 [==============================] - 8s 626us/sample - loss: 0.1069 - mae: 0.2390\n",
      "Epoch 47/50\n",
      "12424/12424 [==============================] - 7s 526us/sample - loss: 0.1068 - mae: 0.2391s - loss: 0.1066 - mae: 0.238\n",
      "Epoch 48/50\n",
      "12424/12424 [==============================] - 8s 654us/sample - loss: 0.1065 - mae: 0.2386\n",
      "Epoch 49/50\n",
      "12424/12424 [==============================] - 8s 642us/sample - loss: 0.1061 - mae: 0.2378\n",
      "Epoch 50/50\n",
      "12424/12424 [==============================] - 8s 607us/sample - loss: 0.1060 - mae: 0.2381\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1), input_shape = [None]),\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu'),\n",
    "    #tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
    "    #tf.keras.layers.SimpleRNN(40, return_sequences = True),\n",
    "    #tf.keras.layers.SimpleRNN(20),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(5,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "model1.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5), metrics = ['mae'])\n",
    "history1 = model1.fit(X_train,y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8.635335 ],\n",
       "        [8.519801 ],\n",
       "        [8.479008 ],\n",
       "        [7.8738866],\n",
       "        [7.8289075]], dtype=float32),\n",
       " array([[8.54500289],\n",
       "        [8.37047041],\n",
       "        [8.69484149],\n",
       "        [7.71760729],\n",
       "        [7.7403941 ]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model1.predict(X_test)\n",
    "predictions[:5], y_test.to_numpy()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10240219293340935, 0.23597976988353195)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_squared_error(predictions, y_test), mean_absolute_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
