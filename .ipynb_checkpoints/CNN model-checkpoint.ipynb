{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from scipy import stats\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_price_1</th>\n",
       "      <th>living_space_in_m2</th>\n",
       "      <th>number_of_rooms_1</th>\n",
       "      <th>floor_1</th>\n",
       "      <th>contruction_year_1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pickup cluster</th>\n",
       "      <th>Attikawohnungen</th>\n",
       "      <th>Dachgeschosswohnungen</th>\n",
       "      <th>...</th>\n",
       "      <th>Lofts</th>\n",
       "      <th>Maisonettes</th>\n",
       "      <th>Penthouse</th>\n",
       "      <th>RohdachbÃ¶den</th>\n",
       "      <th>Terrassenwohnungen</th>\n",
       "      <th>Wohnungen</th>\n",
       "      <th>terrasse_1</th>\n",
       "      <th>balkon_1</th>\n",
       "      <th>garten_1</th>\n",
       "      <th>Aufzug_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25580</th>\n",
       "      <td>139000.0</td>\n",
       "      <td>32.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1906</td>\n",
       "      <td>0.915720</td>\n",
       "      <td>0.234394</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21432</th>\n",
       "      <td>340900.0</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.917209</td>\n",
       "      <td>0.234087</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7630</th>\n",
       "      <td>465282.0</td>\n",
       "      <td>61.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.915361</td>\n",
       "      <td>0.230429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase_price_1  living_space_in_m2  number_of_rooms_1  floor_1  \\\n",
       "25580          139000.0               32.67                1.0      2.0   \n",
       "21432          340900.0               49.00                1.0      1.6   \n",
       "7630           465282.0               61.02                2.0      1.0   \n",
       "\n",
       "       contruction_year_1       lat       lon  pickup cluster  \\\n",
       "25580                1906  0.915720  0.234394               2   \n",
       "21432                1921  0.917209  0.234087               2   \n",
       "7630                 2003  0.915361  0.230429               0   \n",
       "\n",
       "       Attikawohnungen   Dachgeschosswohnungen  ...  Lofts  Maisonettes  \\\n",
       "25580                 0                      0  ...      0            0   \n",
       "21432                 0                      0  ...      0            0   \n",
       "7630                  0                      0  ...      0            0   \n",
       "\n",
       "       Penthouse  RohdachbÃ¶den  Terrassenwohnungen  Wohnungen  terrasse_1  \\\n",
       "25580          0              0                   0          0           0   \n",
       "21432          0              0                   0          1           0   \n",
       "7630           0              0                   0          0           0   \n",
       "\n",
       "       balkon_1  garten_1  Aufzug_1  \n",
       "25580         0         0         0  \n",
       "21432         0         0         0  \n",
       "7630          1         1         0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'F:\\amruth\\norm_price.csv', encoding = 'iso-8859-1')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['living_space_in_m2', 'number_of_rooms_1', 'floor_1',\n",
       "       'contruction_year_1', 'lat', 'lon', 'pickup cluster',\n",
       "       'Attikawohnungen ', 'Dachgeschosswohnungen', 'Erdgeschosswohnungen',\n",
       "       'Etagenwohnungen', 'Lofts', 'Maisonettes', 'Penthouse', 'RohdachbÃ¶den',\n",
       "       'Terrassenwohnungen', 'Wohnungen', 'terrasse_1', 'balkon_1', 'garten_1',\n",
       "       'Aufzug_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data[['purchase_price_1']]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20703, 21), (20703, 1), (6901, 21))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1), input_shape = [None]),\n",
    "    tf.keras.layers.Conv1D(filters = 128, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu'),\n",
    "    #tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1)),\n",
    "    tf.keras.layers.LSTM(128, return_sequences = True),\n",
    "    tf.keras.layers.LSTM(64, return_sequences = True),\n",
    "    tf.keras.layers.SimpleRNN(80, return_sequences = True),\n",
    "    tf.keras.layers.SimpleRNN(40),\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(50,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(20,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epochs: 1e-5 * 10**(epochs / 20))\n",
    "model.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20703 samples, validate on 6901 samples\n",
      "Epoch 1/50\n",
      "20703/20703 [==============================] - 31s 1ms/sample - loss: 205460078290.4831 - mae: 402645.5625 - val_loss: 208246882572.2788 - val_mae: 405312.8125\n",
      "Epoch 2/50\n",
      "20703/20703 [==============================] - 27s 1ms/sample - loss: 205459866047.9227 - mae: 402645.2500 - val_loss: 208246695555.8394 - val_mae: 405312.6250\n",
      "Epoch 3/50\n",
      "20703/20703 [==============================] - 24s 1ms/sample - loss: 205459647052.4921 - mae: 402645.0625 - val_loss: 208246421935.2047 - val_mae: 405312.5000\n",
      "Epoch 4/50\n",
      "11520/20703 [===============>..............] - ETA: 7s - loss: 204095809854.5778 - mae: 400975.9062"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e35dbbc1e615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history=model.fit(X_train,y_train, validation_data = (X_test, y_test), \n\u001b[1;32m----> 2\u001b[1;33m                   batch_size  =256, epochs=50, callbacks = [lr_schedule])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3217\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[0;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 415\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    416\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train, validation_data = (X_test, y_test), \n",
    "                  batch_size  =256, epochs=50, callbacks = [lr_schedule])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x207baf55ac8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD+CAYAAAAj1F4jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZwklEQVR4nO3dfXRc9X3n8fd3RpJlCz1YsiRkyUZ+wmDjB0DBBrrUPCghpzSmD2yT3eS4Xc662SR70nO6u3V3/9jtyTlbzp6zPe1Je5q6SYq3TcIGQmo3sGmMgYQUAsjG2GBDZGywZQtJNn62ZVma7/6hKyOMHmZGM7pz73xe5+jM3Dt3Zj7iMh9d/+7DmLsjIiLRkwg7gIiIZEcFLiISUSpwEZGIUoGLiESUClxEJKJU4CIiETVpgZvZUjPbPernjJn9gZnVmtl2M+sMbmdPR2ARERlmmRwHbmZJ4CiwBvgy8IG7P2Jmm4DZ7v5H+YkpIiJXy7TAPwn8d3e/08zeBta5e7eZNQHPu/vSiZ4/Z84cb21tnVJgEZFis3PnzuPuXn/1/JIMX+ezwPeC+43u3g0QlHjDZE9ubW2lo6Mjw7cUESluZvbeWPPT3olpZmXAZ4DHM3zjjWbWYWYdfX19mTxVREQmkMlRKJ8Gdrl7TzDdEwydENz2jvUkd9/s7m3u3lZf/7F/AYiISJYyKfDP8eHwCcA2YENwfwOwNVehRERkcmkVuJnNAtqBJ0fNfgRoN7PO4LFHch9PRETGk9ZOTHe/ANRdNe8EcG8+QomIyOR0JqaISERFosC7Tl7gmX09ky8oIlJEIlHgX99xgK8+9hoXB4bCjiIiUjAiUeDrb57L+YEhntmvrXARkRGRKPA1C+q4tqqcrbuPhh1FRKRgRKLAkwnj11c18fzbfZw8PxB2HBGRghCJAgdYv7qZwZTz1N7usKOIiBSEyBT48rlVLG64RsMoIiKByBS4mfHg6rm8+u5Juk5eCDuOiEjoIlPgMDyMArB197GQk4iIhC9SBT6vdha3XjebrbuPkskXUYiIxFGkChzgwdVz+WXPOfZ3nw07iohIqCJX4L+2ci4lCdPOTBEpepEr8NqKMu66vp5trx8jldIwiogUr8gVOMD61XPpPt3Py4c+CDuKiEhoIlng7csamVWW1DCKiBS1SBb4rLISPrX8Wp7e282lQV2hUESKUyQLHIaHUc70D/LcW/qmexEpTpEt8F9ZPIc515RpGEVEilZkC7wkmeCBlXPZ8VYvZ/svhx1HRGTaRbbAAT65vJGBwRSv6GgUESlCaRW4mdWY2RNm9paZ7Tez282s1sy2m1lncDs732Gvdsv82ZQlEzqcUESKUrpb4H8B/NjdbwBWAfuBTcAOd18C7Aimp1V5aZLV82r4xcET0/3WIiKhm7TAzawKuAv4FoC7D7j7KWA9sCVYbAvwYL5CTmTNwlreOHpa4+AiUnTS2QJfCPQBf2dmr5nZN82sAmh0926A4LZhrCeb2UYz6zCzjr6+3B/yt2ZBHSmHjvdO5vy1RUQKWToFXgLcAvy1u98MnCeD4RJ33+zube7eVl9fn2XM8d1yXQ0lCePlgxoHF5Hikk6BdwFd7v5yMP0Ew4XeY2ZNAMFtb34iTmxWWQmr5tXw8iGNg4tIcZm0wN39feCImS0NZt0L7AO2ARuCeRuArXlJmIY1C2rZ03Wa85cGw4ogIjLt0j0K5T8C3zGzPcBq4H8CjwDtZtYJtAfToVizsI6hlLNT4+AiUkRK0lnI3XcDbWM8dG9u42Tn1utmk0wYLx86wV3X536cXUSkEEX6TMwR18woYUVztXZkikhRiUWBw/Dx4K93neLigC4vKyLFITYFvnZBHZeHnF2HNQ4uIsUhNgXe1jqbhMHLOq1eRIpEbAq8sryUm5qr+YUubCUiRSI2BQ7Dx4PvPnyK/ssaBxeR+ItZgdcxMJTitcOnwo4iIpJ3sSrwTyyoxQydVi8iRSFWBV49s5RlTVU6HlxEikKsChyGh1F2HT7JpUGNg4tIvMWvwBfWcmkwxetHTocdRUQkr2JX4Le11gI6HlxE4i92BT67oowbrq3UFx2LSOzFrsAB1i6sY+d7JxkYTIUdRUQkb2JZ4GsW1HLx8hB7j+p4cBGJr1gWeFswDq4TekQkzmJZ4PWVM2iqLmdPl45EEZH4imWBA6xoruaNoypwEYmv2Bb4ypZqDh4/z5n+y2FHERHJi9gW+E3N1QDaCheR2EqrwM3sXTPba2a7zawjmFdrZtvNrDO4nZ3fqJlZoQIXkZjLZAv8bndf7e4j306/Cdjh7kuAHcF0wai7ZgbNNTO1I1NEYmsqQyjrgS3B/S3Ag1OPk1srW6rZqy1wEYmpdAvcgZ+Y2U4z2xjMa3T3boDgtmGsJ5rZRjPrMLOOvr6+qSfOwE3N1bx34gKnL2hHpojET7oFfqe73wJ8Gviymd2V7hu4+2Z3b3P3tvr6+qxCZmtlSzAOfkxb4SISP2kVuLsfC257gR8CtwE9ZtYEENz25itktkZ2ZGocXETiaNICN7MKM6scuQ98EngD2AZsCBbbAGzNV8hs1cwqY37tLF0TRURiqSSNZRqBH5rZyPLfdfcfm9mrwPfN7GHgMPBQ/mJmb0VzNa93qcBFJH4mLXB3PwisGmP+CeDefITKpRUt1Ty1t5uT5weYXVEWdhwRkZyJ7ZmYI1YG4+A6nFBE4ib2Bb5cBS4iMRX7Aq+eWUpr3Sz2aBxcRGIm9gUOsKKlhjeOngk7hohIThVFga9sruboqYscP3cp7CgiIjlTFAV+k8bBRSSGiqTAqwDYqzMyRSRGiqLAK8tLWVhfoS1wEYmVoihwGB4H1xa4iMRJ0RT4Tc3VvH+mn94z/WFHERHJiaIp8JUtNYB2ZIpIfBRNgS+fW4WZClxE4qNoCrxiRgmL6q/ROLiIxEbRFDgM78jcc/Q07h52FBGRKSuqAl/RUk3f2Uv0nNEZmSISfUVV4CPfkalxcBGJg6Iq8GVN1SQMXZlQRGKhqAp8ZlmS6xsreV07MkUkBoqqwAFWtdSwp+uUdmSKSOQVXYGvnFfNqQuXOfzBhbCjiIhMSdoFbmZJM3vNzH4UTNea2XYz6wxuZ+cvZu6sCs7I1DCKiERdJlvgXwX2j5reBOxw9yXAjmC64C29tpIZJQleP6IdmSISbWkVuJm1AL8GfHPU7PXAluD+FuDB3EbLj9JkguVzq3QkiohEXrpb4H8O/BcgNWpeo7t3AwS3DTnOljcrW2rYe/Q0g0OpyRcWESlQkxa4mT0A9Lr7zmzewMw2mlmHmXX09fVl8xI5t3peDf2XU3T2ngs7iohI1tLZAr8T+IyZvQs8BtxjZv8A9JhZE0Bw2zvWk919s7u3uXtbfX19jmJPzcgZmRoHF5Eom7TA3f2P3b3F3VuBzwLPuvvngW3AhmCxDcDWvKXMsda6CqrKS3QkiohE2lSOA38EaDezTqA9mI6ERMJY2VKjLXARibSSTBZ29+eB54P7J4B7cx9peqyaV803fnqQ/stDlJcmw44jIpKxojsTc8TKlhqGUs6bxzSMIiLRVLQFvnpecEbmERW4iERT0RZ4Y1U511aV87pO6BGRiCraAofhwwn36EgUEYmooi7wVfNqOHT8PKcvXA47iohIxoq7wIMrE+45qmEUEYmeoi7wFTojU0QirKgLvHpmKQvnVOiMTBGJpKIucBgeB9cWuIhEUdEX+MqWanrPXuL90/1hRxERyUjRF/iq4ISe3doKF5GIKfoCX9ZURUnC9A09IhI5RV/g5aVJbmiq1BmZIhI5RV/gMHxhqz1dp0mlPOwoIiJpU4EDq1tqONs/yKET58OOIiKSNhU4H+7I1Di4iESJChxY3HANs8qSurSsiESKChxIJoybmqvZdfhk2FFERNKmAg+sXVjHG0dPc/qirkwoItGgAg/csaiOlMMrhz4IO4qISFpU4IGb59dQXprgxXeOhx1FRCQtkxa4mZWb2Stm9rqZvWlmfxLMrzWz7WbWGdzOzn/c/JlRkuQTrbW8eOBE2FFERNKSzhb4JeAed18FrAbuN7O1wCZgh7svAXYE05F2+6I63u45S9/ZS2FHERGZ1KQF7sPOBZOlwY8D64EtwfwtwIN5STiN7lg0B4BfHNRWuIgUvrTGwM0saWa7gV5gu7u/DDS6ezdAcNswznM3mlmHmXX09fXlKnde3DS3isoZJRoHF5FISKvA3X3I3VcDLcBtZnZTum/g7pvdvc3d2+rr67PNOS1KkgnWLKzjxXe0BS4ihS+jo1Dc/RTwPHA/0GNmTQDBbW/O04XgjkV1vHfiAl0nL4QdRURkQukchVJvZjXB/ZnAfcBbwDZgQ7DYBmBrvkJOpzsW1wHwkrbCRaTApbMF3gQ8Z2Z7gFcZHgP/EfAI0G5mnUB7MB15Sxsrqaso0zCKiBS8kskWcPc9wM1jzD8B3JuPUGEyM25fVMeL7xzH3TGzsCOJiIxJZ2KO4Y5Fc+g5c4mDx3V9cBEpXCrwMdwZjIO/eECHE4pI4VKBj2F+7Syaa2ZqHFxECpoKfAwj4+AvHTyh78kUkYKlAh/HHYvqOHXhMvu6z4QdRURkTCrwcYxcF0XHg4tIoVKBj+Pa6nIW1lfouigiUrBU4BO4Y1Edrxz6gMtDqbCjiIh8jAp8AncumsP5gSH2dJ0KO4qIyMeowCewduHI8eAaBxeRwqMCn8DsijKWNVXpeHARKUgq8EncubiOne+d5PylwbCjiIh8hAp8Enff0MDAUIoXOgv724REpPiowCdxW2st1TNL2b4vFt9XISIxogKfREkywT03NPDsWz0M6nBCESkgKvA03HdjIycvXGbneyfDjiIicoUKPA2/urSesmSCZ/b3hB1FROQKFXgarplRwtpFdWzf14O7rk4oIoVBBZ6m9mWNvHviAu/0nQs7iogIoAJP2303NgDwk30aRhGRwjBpgZvZPDN7zsz2m9mbZvbVYH6tmW03s87gdnb+44anqXomK5qreUYFLiIFIp0t8EHgD939RmAt8GUzWwZsAna4+xJgRzAda/fd2MhrR07Rd/ZS2FFERCYvcHfvdvddwf2zwH6gGVgPbAkW2wI8mK+QhaJ9WSPusENHo4hIAchoDNzMWoGbgZeBRnfvhuGSBxpyHa7Q3NhUSXPNTB1OKCIFIe0CN7NrgB8Af+DuaX9RpJltNLMOM+vo64v29UTMjPZljbzQeZwLA7q4lYiEK60CN7NShsv7O+7+ZDC7x8yagsebgDEvFuLum929zd3b6uvrc5E5VO3LGrk0mOLnnfqqNREJVzpHoRjwLWC/u//ZqIe2ARuC+xuArbmPV3huW1BLZXkJ23U0ioiErCSNZe4EvgDsNbPdwbz/CjwCfN/MHgYOAw/lJ2JhKU0muHtpA8++1ctQykkmLOxIIlKkJi1wd/85MF5L3ZvbONFw37JGtr1+jNcOn6SttTbsOCJSpHQmZhbWLa2nJGEaRhGRUKnAs1BVXsrahXVs1+GEIhIiFXiW2pc1crDvPJ09Z8OOIiJFSgWepU+vuJZkwvjBrqNhRxGRIqUCz1JDZTnrrq/nyV1d+qo1EQmFCnwKHmproffsJV7QST0iEgIV+BTcc0MjtRVlPL7zSNhRRKQIqcCnoKwkwfrVc3lmXy8nzw+EHUdEiowKfIp++9YWBoZSbN2tnZkiMr1U4FO0fG41y5qqeHxnV9hRRKTIqMBz4KG2Ft48doZ9x9K+yq6IyJSpwHNg/epmSpPGE9oKF5FppALPgdqKMu67sZF/3H2UgUEdEy4i00MFniMPtbXwwfkBnn1rzO+1EBHJORV4jty1pJ6Gyhk8oWPCRWSaqMBzpCSZ4Dduaea5t/voPdsfdhwRKQIq8Bx66NZ5DKWcf3xNx4SLSP6pwHNoccM13Dy/hsc7unD3sOOISMypwHPsoVvn0dl7jt1HToUdRURiTgWeYw+saqKiLMm3/+XdsKOISMypwHOsqryUz99+HU/tOcah4+fDjiMiMTZpgZvZt82s18zeGDWv1sy2m1lncDs7vzGj5eFfWUBJMsHf/PSdsKOISIylswX+KHD/VfM2ATvcfQmwI5iWQENlOb/TNo8f7Oqi+/TFsOOISExNWuDu/jPgg6tmrwe2BPe3AA/mOFfkbbxrISmHv/3ZobCjiEhMZTsG3uju3QDBbcN4C5rZRjPrMLOOvr6+LN8ueubVzmL96rl875XDnDh3Kew4IhJDed+J6e6b3b3N3dvq6+vz/XYF5UvrFtE/OMSjL74bdhQRiaFsC7zHzJoAgltdwWkMixsq+eSyRra8+C5n+y+HHUdEYibbAt8GbAjubwC25iZO/Hxp3WLO9A/ynZcPhx1FRGImncMIvwe8BCw1sy4zexh4BGg3s06gPZiWMayaV8O/WjKHb75wiP7LQ2HHEZEYSecolM+5e5O7l7p7i7t/y91PuPu97r4kuL36KBUZ5UvrFnP83CUe79ClZkUkd3Qm5jRYu7CWW+bX8I2fHuTykL6xR0RyQwU+DcyML9+9mKOnLrJ197Gw44hITKjAp8k9NzSwfG4V//snb3NhYDDsOCISAyrwaWJm/MlnltN9up+vP3sg7DgiEgMq8GnU1lrLb93SwjdfOMg7fefCjiMiEacCn2abPn0D5aVJ/se2N/WtPSIyJSrwaVZfOYM/bL+eFzqP8//eeD/sOCISYSrwEHx+7XXc2FTF1360Tzs0RSRrKvAQlCQTfG29dmiKyNSowEOiHZoiMlUq8BBph6aITIUKPESjd2j+WDs0RSRDKvCQjezQ/OMf7mVv1+mw44hIhKjAQ1aSTPA3n7+VirIS/s3f/oKOd3VhRxFJjwq8AMyvm8XjX7ydOZUz+MK3XuHFA8fDjiQiEaACLxBza2byf39/LfNrZ/G7j77Ks2/1hB1JRAqcCryANFSW89jGtSxtrOT3/34nT+/tDjuSiBQwFXiBmV1Rxnf+/RpWttTwle/u4vGOIzrEUETGpAIvQFXlpfz9w7exdmEd//mJPfz2N17iubd6VeQi8hEq8AI1q6yEv/u9T/C19ct5/3Q/v/foqzzw9Z/z4ze6SaVU5CIyxQI3s/vN7G0zO2Bmm3IVSobNKEnyhdtbee4/reN//dZKzl8a5Iv/sItP/fnP+MHOLrpPX9RWuUgRs2wLwMySwC+BdqALeBX4nLvvG+85bW1t3tHRkdX7CQwOpXhqbzd/9dwBftkzfP2UqvISll5bGfxUsbSxktqKMmaWJZlVmmRmWZIZJQnMLOT0IpItM9vp7m1Xzy+ZwmveBhxw94PBGzwGrAfGLXCZmpJkgvWrm/n1lXPZdfgk+7rP8Pb7Z3n7/bNsfe0YZy8dHvN5ZjCzNElpMoEZJMxI2PDXvCWCaYMrJZ9IgDHqsY/djiwf/GDBbTBzrAwT/F7j/W2xK4/bVdMjj9uVmVfyjGT5yP0Pf5fRv/fVy370tT4MNTreVP8OfvS1wvmjms1GW66ypvve6bxfpr9Hrv+tOlbC0e9xdbwv/uoils2tymmGqRR4M3Bk1HQXsObqhcxsI7ARYP78+VN4OxmRSBhtrbW0tdZemefuHDvdT2fPWc70D3JxYJCLA0NcuDxE/8AQFwaGGEw5KR/+cYeUDz9vKOU4w//DOQ5OsNzw/5DDyzup1IfzwYPlh19j5PljmeiDM9mHcORhD17lyrR/dJ4DngIn9bFcqSBcavTvNeq/w8iyV7KOivTRD+TUKmCiD/d0y6SPs8nq+PAfxSze2z/y33/810nntT62fGaLj2ui/yTj/ZE+2385R+/+oakU+GR/gIZnuG8GNsPwEMoU3k8mYGY018ykuWZm2FFEZJpMZSdmFzBv1HQLcGxqcUREJF1TKfBXgSVmtsDMyoDPAttyE0tERCaT9RCKuw+a2VeAfwaSwLfd/c2cJRMRkQlNZQwcd38aeDpHWUREJAM6E1NEJKJU4CIiEaUCFxGJKBW4iEhEZX0tlKzezKwPeC+YrAbG+hbf8ebPAQrxu8bGyxvma2b6/HSXn2y5iR7P9LFiWt9Tfd1CXN8TPR6lz3ihrO/r3L3+Y3M9OE16un+AzRnO7wgraza/R5ivmenz011+suUmejzTx4ppfU/1dQtxfU/0eJQ+44W4vkf/hDmE8k8Zzi9U+cg71dfM9PnpLj/ZchM9nu1jhSZfWafyuoW4vid6XOs7R687rUMoU2FmHT7G5RQlnrS+i4/WeeaitBNzc9gBZFppfRcfrfMMRWYLXEREPipKW+AiIjKKClxEJKJU4CIiERWLAjezdWb2gpl9w8zWhZ1H8s/MKsxsp5k9EHYWyS8zuzH4bD9hZv8h7DyFJPQCN7Nvm1mvmb1x1fz7zextMztgZpsmeRkHzgHlDH9TkBSoHK1vgD8Cvp+flJIruVjf7r7f3b8I/GtAhxmOEvpRKGZ2F8Pl+3/c/aZgXhL4JdDOcCG/CnyO4S+O+NOrXuLfAcfdPWVmjcCfufu/na78kpkcre+VDJ92Xc7wuv/R9KSXTOVifbt7r5l9BtgE/KW7f3e68he6KX2hQy64+8/MrPWq2bcBB9z9IICZPQasd/c/BSb6J/NJYEY+ckpu5GJ9m9ndQAWwDLhoZk+7eyqvwSUrufp8u/s2YJuZPQWowAOhF/g4moEjo6a7gDXjLWxmvwl8CqgB/jK/0SQPMlrf7v7fAMzsdwn+9ZXXdJJrmX6+1wG/yfDGmb4BbJRCLXAbY964Yz3u/iTwZP7iSJ5ltL6vLOD+aO6jyDTI9PP9PPB8vsJEWeg7McfRBcwbNd0CHAspi+Sf1ndx0frOkUIt8FeBJWa2wMzKgM8C20LOJPmj9V1ctL5zJPQCN7PvAS8BS82sy8wedvdB4CvAPwP7ge+7+5th5pTc0PouLlrf+RX6YYQiIpKd0LfARUQkOypwEZGIUoGLiESUClxEJKJU4CIiEaUCFxGJKBW4iEhEqcBFRCJKBS4iElH/H5WtNDkG4RNtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = 1e-5 * (10 ** (np.arange(50) / 20))\n",
    "plt.semilogx(lrs, history.history[\"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12424 samples, validate on 319 samples\n",
      "Epoch 1/100\n",
      "12424/12424 [==============================] - 3s 253us/sample - loss: 64.1464 - mae: 7.9943 - val_loss: 56.4359 - val_mae: 7.4985\n",
      "Epoch 2/100\n",
      "12424/12424 [==============================] - 2s 185us/sample - loss: 46.8545 - mae: 6.8192 - val_loss: 36.3683 - val_mae: 6.0134\n",
      "Epoch 3/100\n",
      "12424/12424 [==============================] - 2s 186us/sample - loss: 29.4815 - mae: 5.4011 - val_loss: 22.8278 - val_mae: 4.7550\n",
      "Epoch 4/100\n",
      "12424/12424 [==============================] - 2s 191us/sample - loss: 18.3071 - mae: 4.2445 - val_loss: 13.7061 - val_mae: 3.6714\n",
      "Epoch 5/100\n",
      "12424/12424 [==============================] - 2s 192us/sample - loss: 10.9034 - mae: 3.2620 - val_loss: 8.0397 - val_mae: 2.7942\n",
      "Epoch 6/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 6.2774 - mae: 2.4534 - val_loss: 4.4268 - val_mae: 2.0499\n",
      "Epoch 7/100\n",
      "12424/12424 [==============================] - 3s 235us/sample - loss: 3.3446 - mae: 1.7603 - val_loss: 2.2419 - val_mae: 1.4215\n",
      "Epoch 8/100\n",
      "12424/12424 [==============================] - 3s 230us/sample - loss: 1.5860 - mae: 1.1728 - val_loss: 1.0093 - val_mae: 0.9202\n",
      "Epoch 9/100\n",
      "12424/12424 [==============================] - 3s 235us/sample - loss: 0.7568 - mae: 0.7840 - val_loss: 0.5158 - val_mae: 0.6315\n",
      "Epoch 10/100\n",
      "12424/12424 [==============================] - 3s 222us/sample - loss: 0.4044 - mae: 0.5531 - val_loss: 0.3181 - val_mae: 0.4676\n",
      "Epoch 11/100\n",
      "12424/12424 [==============================] - 3s 231us/sample - loss: 0.2670 - mae: 0.4289 - val_loss: 0.2515 - val_mae: 0.3925\n",
      "Epoch 12/100\n",
      "12424/12424 [==============================] - 3s 221us/sample - loss: 0.2194 - mae: 0.3711 - val_loss: 0.2320 - val_mae: 0.3618\n",
      "Epoch 13/100\n",
      "12424/12424 [==============================] - 3s 219us/sample - loss: 0.2028 - mae: 0.3463 - val_loss: 0.2248 - val_mae: 0.3489\n",
      "Epoch 14/100\n",
      "12424/12424 [==============================] - 3s 224us/sample - loss: 0.1942 - mae: 0.3335 - val_loss: 0.2177 - val_mae: 0.3406\n",
      "Epoch 15/100\n",
      "12424/12424 [==============================] - 3s 225us/sample - loss: 0.1855 - mae: 0.3239 - val_loss: 0.2092 - val_mae: 0.3336\n",
      "Epoch 16/100\n",
      "12424/12424 [==============================] - 3s 236us/sample - loss: 0.1782 - mae: 0.3159 - val_loss: 0.2032 - val_mae: 0.3281\n",
      "Epoch 17/100\n",
      "12424/12424 [==============================] - 3s 279us/sample - loss: 0.1727 - mae: 0.3104 - val_loss: 0.1982 - val_mae: 0.3233\n",
      "Epoch 18/100\n",
      "12424/12424 [==============================] - 3s 259us/sample - loss: 0.1677 - mae: 0.3053 - val_loss: 0.1933 - val_mae: 0.3189\n",
      "Epoch 19/100\n",
      "12424/12424 [==============================] - 3s 255us/sample - loss: 0.1630 - mae: 0.3007 - val_loss: 0.1886 - val_mae: 0.3154\n",
      "Epoch 20/100\n",
      "12424/12424 [==============================] - 3s 237us/sample - loss: 0.1590 - mae: 0.2970 - val_loss: 0.1858 - val_mae: 0.3131\n",
      "Epoch 21/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 0.1572 - mae: 0.2946 - val_loss: 0.1855 - val_mae: 0.3128\n",
      "Epoch 22/100\n",
      "12424/12424 [==============================] - 3s 215us/sample - loss: 0.1567 - mae: 0.2937 - val_loss: 0.1852 - val_mae: 0.3128\n",
      "Epoch 23/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 0.1566 - mae: 0.2933 - val_loss: 0.1850 - val_mae: 0.3127\n",
      "Epoch 24/100\n",
      "12424/12424 [==============================] - 3s 245us/sample - loss: 0.1564 - mae: 0.2931 - val_loss: 0.1848 - val_mae: 0.3127\n",
      "Epoch 25/100\n",
      "12424/12424 [==============================] - 3s 222us/sample - loss: 0.1563 - mae: 0.2930 - val_loss: 0.1848 - val_mae: 0.3124\n",
      "Epoch 26/100\n",
      "12424/12424 [==============================] - 3s 224us/sample - loss: 0.1560 - mae: 0.2927 - val_loss: 0.1843 - val_mae: 0.3121\n",
      "Epoch 27/100\n",
      "12424/12424 [==============================] - 3s 230us/sample - loss: 0.1556 - mae: 0.2925 - val_loss: 0.1838 - val_mae: 0.3115\n",
      "Epoch 28/100\n",
      "12424/12424 [==============================] - 3s 235us/sample - loss: 0.1551 - mae: 0.2919 - val_loss: 0.1831 - val_mae: 0.3107\n",
      "Epoch 29/100\n",
      "12424/12424 [==============================] - 3s 234us/sample - loss: 0.1545 - mae: 0.2915 - val_loss: 0.1814 - val_mae: 0.3091\n",
      "Epoch 30/100\n",
      "12424/12424 [==============================] - 3s 225us/sample - loss: 0.1533 - mae: 0.2905 - val_loss: 0.1807 - val_mae: 0.3083\n",
      "Epoch 31/100\n",
      "12424/12424 [==============================] - 3s 222us/sample - loss: 0.1523 - mae: 0.2894 - val_loss: 0.1790 - val_mae: 0.3072\n",
      "Epoch 32/100\n",
      "12424/12424 [==============================] - 3s 221us/sample - loss: 0.1512 - mae: 0.2883 - val_loss: 0.1770 - val_mae: 0.3050\n",
      "Epoch 33/100\n",
      "12424/12424 [==============================] - 3s 222us/sample - loss: 0.1495 - mae: 0.2866 - val_loss: 0.1750 - val_mae: 0.3031\n",
      "Epoch 34/100\n",
      "12424/12424 [==============================] - 3s 237us/sample - loss: 0.1479 - mae: 0.2848 - val_loss: 0.1726 - val_mae: 0.3008\n",
      "Epoch 35/100\n",
      "12424/12424 [==============================] - 3s 238us/sample - loss: 0.1461 - mae: 0.2830 - val_loss: 0.1704 - val_mae: 0.2986\n",
      "Epoch 36/100\n",
      "12424/12424 [==============================] - 3s 247us/sample - loss: 0.1444 - mae: 0.2812 - val_loss: 0.1672 - val_mae: 0.2990\n",
      "Epoch 37/100\n",
      "12424/12424 [==============================] - 3s 234us/sample - loss: 0.1425 - mae: 0.2792 - val_loss: 0.1642 - val_mae: 0.2934\n",
      "Epoch 38/100\n",
      "12424/12424 [==============================] - 3s 250us/sample - loss: 0.1410 - mae: 0.2773 - val_loss: 0.1626 - val_mae: 0.2911\n",
      "Epoch 39/100\n",
      "12424/12424 [==============================] - 3s 236us/sample - loss: 0.1386 - mae: 0.2750 - val_loss: 0.1607 - val_mae: 0.2883\n",
      "Epoch 40/100\n",
      "12424/12424 [==============================] - 3s 259us/sample - loss: 0.1356 - mae: 0.2717 - val_loss: 0.1544 - val_mae: 0.2831\n",
      "Epoch 41/100\n",
      "12424/12424 [==============================] - 3s 279us/sample - loss: 0.1275 - mae: 0.2645 - val_loss: 0.1356 - val_mae: 0.2661\n",
      "Epoch 42/100\n",
      "12424/12424 [==============================] - 3s 267us/sample - loss: 0.1186 - mae: 0.2555 - val_loss: 0.1204 - val_mae: 0.2530\n",
      "Epoch 43/100\n",
      "12424/12424 [==============================] - 3s 265us/sample - loss: 0.1154 - mae: 0.2523 - val_loss: 0.1193 - val_mae: 0.2516\n",
      "Epoch 44/100\n",
      "12424/12424 [==============================] - 3s 231us/sample - loss: 0.1137 - mae: 0.2502 - val_loss: 0.1149 - val_mae: 0.2472\n",
      "Epoch 45/100\n",
      "12424/12424 [==============================] - 3s 244us/sample - loss: 0.1126 - mae: 0.2489 - val_loss: 0.1137 - val_mae: 0.2456\n",
      "Epoch 46/100\n",
      "12424/12424 [==============================] - 3s 259us/sample - loss: 0.1119 - mae: 0.2479 - val_loss: 0.1121 - val_mae: 0.2445\n",
      "Epoch 47/100\n",
      "12424/12424 [==============================] - 3s 269us/sample - loss: 0.1117 - mae: 0.2475 - val_loss: 0.1124 - val_mae: 0.2442\n",
      "Epoch 48/100\n",
      "12424/12424 [==============================] - 4s 284us/sample - loss: 0.1110 - mae: 0.2466 - val_loss: 0.1108 - val_mae: 0.2424\n",
      "Epoch 49/100\n",
      "12424/12424 [==============================] - 3s 258us/sample - loss: 0.1104 - mae: 0.2457 - val_loss: 0.1099 - val_mae: 0.2421\n",
      "Epoch 50/100\n",
      "12424/12424 [==============================] - 3s 254us/sample - loss: 0.1100 - mae: 0.2452 - val_loss: 0.1103 - val_mae: 0.2420\n",
      "Epoch 51/100\n",
      "12424/12424 [==============================] - 3s 252us/sample - loss: 0.1098 - mae: 0.2451 - val_loss: 0.1117 - val_mae: 0.2433\n",
      "Epoch 52/100\n",
      "12424/12424 [==============================] - 3s 247us/sample - loss: 0.1094 - mae: 0.2443 - val_loss: 0.1094 - val_mae: 0.2410\n",
      "Epoch 53/100\n",
      "12424/12424 [==============================] - 3s 245us/sample - loss: 0.1092 - mae: 0.2442 - val_loss: 0.1082 - val_mae: 0.2394\n",
      "Epoch 54/100\n",
      "12424/12424 [==============================] - 3s 245us/sample - loss: 0.1090 - mae: 0.2434 - val_loss: 0.1078 - val_mae: 0.2388\n",
      "Epoch 55/100\n",
      "12424/12424 [==============================] - 3s 246us/sample - loss: 0.1085 - mae: 0.2429 - val_loss: 0.1069 - val_mae: 0.2385\n",
      "Epoch 56/100\n",
      "12424/12424 [==============================] - 3s 244us/sample - loss: 0.1085 - mae: 0.2427 - val_loss: 0.1079 - val_mae: 0.2391\n",
      "Epoch 57/100\n",
      "12424/12424 [==============================] - 3s 244us/sample - loss: 0.1082 - mae: 0.2424 - val_loss: 0.1063 - val_mae: 0.2380\n",
      "Epoch 58/100\n",
      "12424/12424 [==============================] - 3s 245us/sample - loss: 0.1079 - mae: 0.2420 - val_loss: 0.1067 - val_mae: 0.2376\n",
      "Epoch 59/100\n",
      "12424/12424 [==============================] - 3s 244us/sample - loss: 0.1078 - mae: 0.2418 - val_loss: 0.1068 - val_mae: 0.2376\n",
      "Epoch 60/100\n",
      "12424/12424 [==============================] - 3s 246us/sample - loss: 0.1078 - mae: 0.2417 - val_loss: 0.1058 - val_mae: 0.2369\n",
      "Epoch 61/100\n",
      "12424/12424 [==============================] - 3s 252us/sample - loss: 0.1075 - mae: 0.2416 - val_loss: 0.1077 - val_mae: 0.2434\n",
      "Epoch 62/100\n",
      "12424/12424 [==============================] - 3s 244us/sample - loss: 0.1075 - mae: 0.2412 - val_loss: 0.1047 - val_mae: 0.2373\n",
      "Epoch 63/100\n",
      "12424/12424 [==============================] - 3s 248us/sample - loss: 0.1068 - mae: 0.2404 - val_loss: 0.1037 - val_mae: 0.2383\n",
      "Epoch 64/100\n",
      "12424/12424 [==============================] - 3s 255us/sample - loss: 0.1069 - mae: 0.2408 - val_loss: 0.1035 - val_mae: 0.2373\n",
      "Epoch 65/100\n",
      "12424/12424 [==============================] - 3s 213us/sample - loss: 0.1067 - mae: 0.2401 - val_loss: 0.1033 - val_mae: 0.2364\n",
      "Epoch 66/100\n",
      "12424/12424 [==============================] - 2s 197us/sample - loss: 0.1065 - mae: 0.2398 - val_loss: 0.1039 - val_mae: 0.2378\n",
      "Epoch 67/100\n",
      "12424/12424 [==============================] - 3s 233us/sample - loss: 0.1065 - mae: 0.2397 - val_loss: 0.1038 - val_mae: 0.2353\n",
      "Epoch 68/100\n",
      "12424/12424 [==============================] - 3s 219us/sample - loss: 0.1062 - mae: 0.2394 - val_loss: 0.1048 - val_mae: 0.2361\n",
      "Epoch 69/100\n",
      "12424/12424 [==============================] - 3s 220us/sample - loss: 0.1061 - mae: 0.2388 - val_loss: 0.1029 - val_mae: 0.2358\n",
      "Epoch 70/100\n",
      "12424/12424 [==============================] - 3s 215us/sample - loss: 0.1062 - mae: 0.2390 - val_loss: 0.1041 - val_mae: 0.2387\n",
      "Epoch 71/100\n",
      "12424/12424 [==============================] - 3s 212us/sample - loss: 0.1060 - mae: 0.2387 - val_loss: 0.1032 - val_mae: 0.2343\n",
      "Epoch 72/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 0.1057 - mae: 0.2384 - val_loss: 0.1029 - val_mae: 0.2339\n",
      "Epoch 73/100\n",
      "12424/12424 [==============================] - 3s 217us/sample - loss: 0.1059 - mae: 0.2387 - val_loss: 0.1026 - val_mae: 0.2337\n",
      "Epoch 74/100\n",
      "12424/12424 [==============================] - 3s 218us/sample - loss: 0.1057 - mae: 0.2382 - val_loss: 0.1025 - val_mae: 0.2338\n",
      "Epoch 75/100\n",
      "12424/12424 [==============================] - 3s 217us/sample - loss: 0.1056 - mae: 0.2380 - val_loss: 0.1027 - val_mae: 0.2336\n",
      "Epoch 76/100\n",
      "12424/12424 [==============================] - 3s 215us/sample - loss: 0.1054 - mae: 0.2375 - val_loss: 0.1034 - val_mae: 0.2340\n",
      "Epoch 77/100\n",
      "12424/12424 [==============================] - 3s 218us/sample - loss: 0.1057 - mae: 0.2378 - val_loss: 0.1023 - val_mae: 0.2334\n",
      "Epoch 78/100\n",
      "12424/12424 [==============================] - 3s 217us/sample - loss: 0.1053 - mae: 0.2375 - val_loss: 0.1060 - val_mae: 0.2365\n",
      "Epoch 79/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 0.1054 - mae: 0.2374 - val_loss: 0.1028 - val_mae: 0.2332\n",
      "Epoch 80/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 0.1052 - mae: 0.2372 - val_loss: 0.1036 - val_mae: 0.2338\n",
      "Epoch 81/100\n",
      "12424/12424 [==============================] - 3s 215us/sample - loss: 0.1052 - mae: 0.2371 - val_loss: 0.1026 - val_mae: 0.2338\n",
      "Epoch 82/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 0.1050 - mae: 0.2369 - val_loss: 0.1056 - val_mae: 0.2352\n",
      "Epoch 83/100\n",
      "12424/12424 [==============================] - 3s 220us/sample - loss: 0.1058 - mae: 0.2379 - val_loss: 0.1032 - val_mae: 0.2334\n",
      "Epoch 84/100\n",
      "12424/12424 [==============================] - 3s 225us/sample - loss: 0.1049 - mae: 0.2363 - val_loss: 0.1016 - val_mae: 0.2324\n",
      "Epoch 85/100\n",
      "12424/12424 [==============================] - 3s 228us/sample - loss: 0.1049 - mae: 0.2365 - val_loss: 0.1018 - val_mae: 0.2327\n",
      "Epoch 86/100\n",
      "12424/12424 [==============================] - 3s 215us/sample - loss: 0.1047 - mae: 0.2363 - val_loss: 0.1021 - val_mae: 0.2326\n",
      "Epoch 87/100\n",
      "12424/12424 [==============================] - 3s 222us/sample - loss: 0.1048 - mae: 0.2359 - val_loss: 0.1015 - val_mae: 0.2328\n",
      "Epoch 88/100\n",
      "12424/12424 [==============================] - 3s 221us/sample - loss: 0.1047 - mae: 0.2360 - val_loss: 0.1017 - val_mae: 0.2327\n",
      "Epoch 89/100\n",
      "12424/12424 [==============================] - 3s 232us/sample - loss: 0.1046 - mae: 0.2358 - val_loss: 0.1013 - val_mae: 0.2321\n",
      "Epoch 90/100\n",
      "12424/12424 [==============================] - 3s 223us/sample - loss: 0.1046 - mae: 0.2358 - val_loss: 0.1025 - val_mae: 0.2328\n",
      "Epoch 91/100\n",
      "12424/12424 [==============================] - 3s 218us/sample - loss: 0.1045 - mae: 0.2357 - val_loss: 0.1015 - val_mae: 0.2319\n",
      "Epoch 92/100\n",
      "12424/12424 [==============================] - 3s 221us/sample - loss: 0.1043 - mae: 0.2353 - val_loss: 0.1024 - val_mae: 0.2326\n",
      "Epoch 93/100\n",
      "12424/12424 [==============================] - 3s 215us/sample - loss: 0.1045 - mae: 0.2354 - val_loss: 0.1017 - val_mae: 0.2327\n",
      "Epoch 94/100\n",
      "12424/12424 [==============================] - 3s 213us/sample - loss: 0.1043 - mae: 0.2354 - val_loss: 0.1018 - val_mae: 0.2323\n",
      "Epoch 95/100\n",
      "12424/12424 [==============================] - 3s 212us/sample - loss: 0.1042 - mae: 0.2352 - val_loss: 0.1035 - val_mae: 0.2339\n",
      "Epoch 96/100\n",
      "12424/12424 [==============================] - 3s 216us/sample - loss: 0.1040 - mae: 0.2349 - val_loss: 0.1013 - val_mae: 0.2320\n",
      "Epoch 97/100\n",
      "12424/12424 [==============================] - 3s 225us/sample - loss: 0.1042 - mae: 0.2347 - val_loss: 0.1013 - val_mae: 0.2323\n",
      "Epoch 98/100\n",
      "12424/12424 [==============================] - 3s 220us/sample - loss: 0.1041 - mae: 0.2349 - val_loss: 0.1019 - val_mae: 0.2352\n",
      "Epoch 99/100\n",
      "12424/12424 [==============================] - 3s 225us/sample - loss: 0.1039 - mae: 0.2349 - val_loss: 0.1038 - val_mae: 0.2350\n",
      "Epoch 100/100\n",
      "12424/12424 [==============================] - 3s 235us/sample - loss: 0.1041 - mae: 0.2348 - val_loss: 0.1012 - val_mae: 0.2327\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1), input_shape = [None]),\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu'),\n",
    "    #tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1)),\n",
    "    tf.keras.layers.LSTM(32, return_sequences = True),\n",
    "    tf.keras.layers.LSTM(16),\n",
    "    #tf.keras.layers.SimpleRNN(40, return_sequences = True),\n",
    "    #tf.keras.layers.SimpleRNN(20),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(5,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "model1.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5), metrics = ['mae'])\n",
    "history1 = model1.fit(X_train,y_train, validation_data = (X_test, y_test), epochs=100, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8.593707],\n",
       "        [8.417801],\n",
       "        [8.381887],\n",
       "        [7.864384],\n",
       "        [7.711547]], dtype=float32),\n",
       " array([[8.54500289],\n",
       "        [8.37047041],\n",
       "        [8.69484149],\n",
       "        [7.71760729],\n",
       "        [7.7403941 ]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model1.predict(X_test)\n",
    "predictions[:5], y_test.to_numpy()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10117423587019198, 0.23267485336582064)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_squared_error(predictions, y_test), mean_absolute_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x207be802288>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(history.history[\"loss\"])), history.history[\"loss\"][1:])\n",
    "plt.plot(range(1, len(history.history[\"val_loss\"])), history.history[\"val_loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_ftt = X_test.head(10)\n",
    "sqr_ft = sq_ftt['living_area_m2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true [505103.25009856]\n",
      "pred [530312.81884788]\n",
      "true [263377.66665733]\n",
      "pred [276143.1769676]\n",
      "true [311023.10593111]\n",
      "pred [227446.06990606]\n",
      "true [494466.57537998]\n",
      "pred [572639.53865109]\n",
      "true [427684.37845084]\n",
      "pred [415523.13510674]\n",
      "true [382740.51652174]\n",
      "pred [375099.37838924]\n",
      "true [258931.78743056]\n",
      "pred [331610.82022896]\n",
      "true [457060.51131931]\n",
      "pred [285090.92620771]\n",
      "true [459640.83683441]\n",
      "pred [547249.03708035]\n",
      "true [806948.48014018]\n",
      "pred [504201.87983239]\n"
     ]
    }
   ],
   "source": [
    "p = predictions[:10]\n",
    "p = p.tolist()\n",
    "y_test = y_test[:10]\n",
    "\n",
    "y_t = y_test.to_numpy().tolist()\n",
    "y_t, p\n",
    "for i, j, k in zip(y_t, sqr_ft, p):\n",
    "    print('true',np.exp(i) * np.exp(j))\n",
    "    print('pred',np.exp(k) * np.exp(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1948b5cfee7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12209.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1980.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4.04\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "score = model1.predict([[2.0, 2.0, 2.0, 2.0, 12209.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1980.0, 4.04]])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
